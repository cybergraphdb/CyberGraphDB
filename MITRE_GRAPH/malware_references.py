import requests
from bs4 import BeautifulSoup

malware_page_references = []
new_references = []
base_url = "https://attack.mitre.org"


def set_new_refs():
    global new_references
    new_references = []


def get_new_refs():
    return new_references


def _find_references(soup):
    global malware_page_references, new_references
    # Trova la sezione "References" per ID
    # Trova il titolo "References"
    references_title = soup.find(id="references")

    # Inizializza una lista per gli URL estratti
    extracted_urls = []

    # Se il titolo "References" è stato trovato
    if references_title:
        # Trova il div successivo con class "row"
        references_div = references_title.find_next("div", class_="row")

        # Se il div "row" è stato trovato
        if references_div:
            # Trova tutti i tag "a" all'interno di questo div
            links = references_div.find_all("a", href=True)

            # Estrai gli URL dagli attributi "href" dei tag "a"
            extracted_urls = [link["href"] for link in links]

    # Stampa gli URL estratti
    for url in extracted_urls:
        if url not in malware_page_references:
            malware_page_references.append(url)
            new_references.append(url)


def find_malware_references(soup):
    global malware_page_references, new_references
    try:
        print("[!] Searching for direct references ...")
        _find_references(soup)
        print("[!] Searching for groups and compaigns ...")
        handle_groups_compaigns_links(soup)
    except:
        pass
    print("[!!!] +++++ NUMBER OF LINKS SO FAR +++++")
    print(len(malware_page_references))
    count = 1
    for url in new_references:
        str_count = str(count)
        print(f"[{str_count}] - " + url)
        count = count + 1
    return new_references


def handle_groups_compaigns_links(soup):
    try:
        group_names = find_hacker_groups(soup)
        for name in group_names:
            explore_group_references(name)
    except:
        print("[!] No Group found ...")
        pass
    try:
        compaigns_link = find_compaign(soup)
        if compaigns_link:
            for link in compaigns_link:
                explore_compaign_link(link)
    except:
        print("[!] No Compaign found")


def find_compaign(soup):
    tables = soup.find_all("table", class_="table table-bordered table-alternate mt-2")

    # Verifica che ci siano almeno due tabelle con questa classe
    if len(tables) >= 2:
        second_table = tables[1]
        data = []

        # Trova le intestazioni della tabella
        headers = [header.text.strip() for header in second_table.find_all("th")]

        compaings_link = []
        if second_table:
            # Itera sulle righe della tabella
            for row in second_table.find_all("tr"):
                # Trova le colonne di ciascuna riga
                columns = row.find_all("td")
                if columns:
                    row_data = {}
                    for i, header in enumerate(headers):
                        # Estrai il testo e l'attributo href (se presente) dai link
                        link = columns[i].find("a")
                        if link:
                            row_data[header] = link.text.strip()
                            href = link.get("href")
                            if href:
                                row_data[f"{header}_href"] = href
                        else:
                            row_data[header] = columns[i].text.strip()
                    data.append(row_data)

        for row in data:
            id_value = row.get("ID", "N/A")
            name = row.get("ID_href", "N/A")
            description = row.get("Name", "N/A")

            name = base_url + name
            print("\n[!] Retrieving Compaign References Used by Malware: \n")
            """
            print(f'MITRE_ID: {id_value}')
            print(f'Compaign Ref: {name}')
            print(f'Compaign Name: {description}')
            print('-' * 30)
            """
            compaings_link.append(name)

        return compaings_link


def find_hacker_groups(soup):
    global malware_page_references, new_references

    table = soup.find("table", class_="table table-bordered table-alternate mt-2")

    if table:
        # Itera sulle righe della tabella
        group_names = []
        for row in table.find_all("tr"):
            # Trova le colonne di ciascuna riga
            columns = row.find_all("td")

            # Estrai i dati dalle colonne e stampali
            if columns:
                id_value = columns[0].text.strip()
                name = columns[1].find("a")["href"].strip()
                name = base_url + name
                references = [a["href"] for a in columns[2].find_all("a")]
                print("\n[!] Retrieving Hacker Group References Used by Malware: \n")
                """
                print(f'MITRE_ID: {id_value}')
                print(f'Name: {name}')
                print(f'References: {references}')
                print('-' * 30)
                """
                group_names.append(name)
                for reference in references:
                    if reference not in malware_page_references:
                        malware_page_references.append(reference)
                        new_references.append(reference)

        return group_names
    else:
        print("[!] Group Table not found")


def explore_group_references(name):
    response = requests.get(name)
    response.raise_for_status()
    soup = BeautifulSoup(response.text, "html.parser")
    _find_references(soup)


def explore_compaign_link(link):
    response = requests.get(link)
    response.raise_for_status()
    soup = BeautifulSoup(response.text, "html.parser")
    _find_references(soup)
