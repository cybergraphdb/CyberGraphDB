import logging
import requests
from bs4 import BeautifulSoup

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

malware_page_references = []
new_references = []
base_url = "https://attack.mitre.org"

def set_new_refs():
    global new_references
    new_references = []

def get_new_refs():
    return new_references

def _find_references(soup):
    global malware_page_references, new_references
    references_title = soup.find(id="references")

    extracted_urls = []

    if references_title:
        references_div = references_title.find_next("div", class_="row")

        if references_div:
            links = references_div.find_all("a", href=True)
            extracted_urls = [link["href"] for link in links]

    for url in extracted_urls:
        if url not in malware_page_references:
            malware_page_references.append(url)
            new_references.append(url)

def find_malware_references(soup):
    global malware_page_references, new_references
    try:
        logging.info("Searching for direct references ...")
        _find_references(soup)
        logging.info("Searching for groups and campaigns ...")
        handle_groups_campaigns_links(soup)
    except Exception as e:
        logging.error(f"Error while searching for references: {e}")
    logging.info("Number of links found so far: %d", len(malware_page_references))
    for idx, url in enumerate(new_references, start=1):
        logging.info("[%d] - %s", idx, url)
    return new_references

def handle_groups_campaigns_links(soup):
    try:
        group_names = find_hacker_groups(soup)
        for name in group_names:
            explore_group_references(name)
    except Exception as e:
        logging.warning(f"No group found: {e}")
    try:
        campaigns_link = find_campaign(soup)
        if campaigns_link:
            for link in campaigns_link:
                explore_campaign_link(link)
    except Exception as e:
        logging.warning(f"No campaign found: {e}")

def find_campaign(soup):
    tables = soup.find_all("table", class_="table table-bordered table-alternate mt-2")

    if len(tables) >= 2:
        second_table = tables[1]
        data = []

        headers = [header.text.strip() for header in second_table.find_all("th")]

        campaigns_link = []
        if second_table:
            for row in second_table.find_all("tr"):
                columns = row.find_all("td")
                if columns:
                    row_data = {}
                    for i, header in enumerate(headers):
                        link = columns[i].find("a")
                        if link:
                            row_data[header] = link.text.strip()
                            href = link.get("href")
                            if href:
                                row_data[f"{header}_href"] = href
                        else:
                            row_data[header] = columns[i].text.strip()
                    data.append(row_data)

        for row in data:
            id_value = row.get("ID", "N/A")
            name = row.get("ID_href", "N/A")
            description = row.get("Name", "N/A")

            name = base_url + name
            logging.info(f"Retrieving Campaign References Used by Malware: {name}")
            campaigns_link.append(name)

        return campaigns_link

def find_hacker_groups(soup):
    global malware_page_references, new_references

    table = soup.find("table", class_="table table-bordered table-alternate mt-2")

    if table:
        group_names = []
        for row in table.find_all("tr"):
            columns = row.find_all("td")

            if columns:
                id_value = columns[0].text.strip()
                name = columns[1].find("a")["href"].strip()
                name = base_url + name
                references = [a["href"] for a in columns[2].find_all("a")]
                logging.info(f"Retrieving Hacker Group References Used by Malware: {name}")

                group_names.append(name)
                for reference in references:
                    if reference not in malware_page_references:
                        malware_page_references.append(reference)
                        new_references.append(reference)

        return group_names
    else:
        logging.warning("Group table not found")
        return []

def explore_group_references(name):
    response = requests.get(name)
    response.raise_for_status()
    soup = BeautifulSoup(response.text, "html.parser")
    _find_references(soup)

def explore_campaign_link(link):
    response = requests.get(link)
    response.raise_for_status()
    soup = BeautifulSoup(response.text, "html.parser")
    _find_references(soup)
